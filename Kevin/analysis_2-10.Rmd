---
title: "analysis_2-10"
author: "Kevin Ros"
date: "2/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
library(coda)
library(runjags)
library(fastDummies)
data = data.frame(read.csv("../Data-Confidentiality/datasets/CEsample.csv",header=TRUE))
```

```{r}
# EXAMPLE FROM CLASS

# modelString <-"
# model {
# ## sampling
# for (i in 1:N){
# y[i] ~ dnorm(beta0 + beta1*x[i], invsigma2)
# }
# 
# ## priors
# beta0 ~ dnorm(mu0, g0)
# beta1 ~ dnorm(mu1, g1)
# invsigma2 ~ dgamma(a,b)
# sigma <- sqrt(pow(invsigma2,-1))
# }
# "
# 
# y <- as.vector(log(data$TotalIncomeLastYear))
# x <- as.vector(log(data$TotalExpLastQ))
# N <-length(y)
# the_data <- list("y" = y, "x" = x, "N" = N,
#                  "mu0" = 0, "g0" = 0.0001,
#                  "mu1" = 0, "g1" = 0.0001,
#                  "a" = 1, "b" = 1)
# 
# initsfunction <- function(chain){
#   .RNG.seed <- c(1,2)[chain]
#   .RNG.name <- c("base::SuperDuper",
#                  "base::Wichmann-Hill")[chain]
#   return(list(.RNG.seed=.RNG.seed,
#               .RNG.name-.RNG.name))
# }
# ```
# 
# ```{r}
# posterior <- run.jags(modelString,
#                       n.chains = 1,
#                       data = the_data,
#                       monitor = c("beta0","beta1","sigma"),
#                       adapt = 1000,
#                       burnin = 5000,
#                       sample = 5000,
#                       thin = 50)
# plot(posterior, vars = "beta0")
```

```{r}
data$log_TotalExpSTD <- scale(log(data$TotalExpLastQ))
data$log_TotalIncomeSTD <- scale(log(data$TotalIncomeLastYear))
```

```{r}
data$Rural = fastDummies::dummy_cols(data$UrbanRural)[,names(fastDummies::dummy_cols(data$UrbanRural))== ".data_2"]
data$Race_Black = fastDummies::dummy_cols(data$Race)[,names(fastDummies::dummy_cols(data$Race)) == ".data_2"]
data$Race_NA = fastDummies::dummy_cols(data$Race)[,names(fastDummies::dummy_cols(data$Race)) == ".data_3"]
data$Race_Asian = fastDummies::dummy_cols(data$Race)[,names(fastDummies::dummy_cols(data$Race)) == ".data_4"]
data$Race_PI = fastDummies::dummy_cols(data$Race)[,names(fastDummies::dummy_cols(data$Race)) == ".data_5"]
data$Race_M = fastDummies::dummy_cols(data$Race)[,names(fastDummies::dummy_cols(data$Race)) == ".data_6"]
```

```{r}
modelString <-"
model {
## sampling
for (i in 1:N){
y[i] ~ dnorm(beta0 + beta1*x_income[i] + beta2*x_rural[i] +
beta3*x_race_B[i] + beta4*x_race_N[i] +
beta5*x_race_A[i] + beta6*x_race_P[i] +
beta7*x_race_M[i], invsigma2)
}
## priors
beta0 ~ dnorm(mu0, g0)
beta1 ~ dnorm(mu1, g1)
beta2 ~ dnorm(mu2, g2)
beta3 ~ dnorm(mu3, g3)
beta4 ~ dnorm(mu4, g4)
beta5 ~ dnorm(mu5, g5)
beta6 ~ dnorm(mu6, g6)
beta7 ~ dnorm(mu7, g7)
invsigma2 ~ dgamma(a, b)
sigma <- sqrt(pow(invsigma2, -1))
}
"
```

```{r}
y = as.vector(data$log_TotalExpSTD)
x_income = as.vector(data$log_TotalIncomeSTD)
x_rural = as.vector(data$Rural)
x_race_B = as.vector(data$Race_Black)
x_race_N = as.vector(data$Race_NA)
x_race_A = as.vector(data$Race_Asian)
x_race_P = as.vector(data$Race_PI)
x_race_M = as.vector(data$Race_M)
N = length(y) 
```

```{r}
the_data <- list("y" = y, "x_income" = x_income,
                 "x_rural" = x_rural, "x_race_B" = x_race_B,
                 "x_race_N" = x_race_N, "x_race_A" = x_race_A,
                 "x_race_P" = x_race_P, "x_race_M" = x_race_M,
                 "N" = N,
                 "mu0" = 0, "g0" = 1, "mu1" = 0, "g1" = 1,
                 "mu2" = 0, "g2" = 1, "mu3" = 0, "g3" = 1,
                 "mu4" = 0, "g4" = 1, "mu5" = 0, "g5" = 1,
                 "mu6" = 0, "g6" = 1, "mu7" = 0, "g7" = 1,
                 "a" = 1, "b" = 1)
```

```{r}
initsfunction <- function(chain){
  .RNG.seed <- c(1,2)[chain]
  .RNG.name <- c("base::Super-Duper",
                 "base::Wichmann-Hill")[chain]
  return(list(.RNG.seed=.RNG.seed,
              .RNG.name=.RNG.name))
}
```

```{r}
posterior_MLR <- run.jags(modelString,
                      n.chains = 1,
                      data = the_data,
                      monitor = c("beta0", "beta1", "beta2",
                                  "beta3", "beta4", "beta5",
                                  "beta6", "beta7", "sigma"),
                      adapt = 1000,
                      burnin = 5000,
                      sample = 5000,
                      thin = 1,
                      inits = initsfunction)
```

```{r}
summary(posterior_MLR)
```

```{r}
post <- as.mcmc(posterior_MLR)
```




```{r}
synthesize <- function(X, index, n){
  mean_Y <- post[index, "beta0"] + X$x_income * post[index, "beta1"] + X$x_rural * post[index, "beta2"] + X$x_race_B * post[index, "beta3"] +  X$x_race_N * post[index, "beta4"] +  X$x_race_A * post[index,   "beta5"] +  X$x_race_P * post[index, "beta6"] +  X$x_race_M * post[index, "beta7"]
  synthetic_Y <- rnorm(n,mean_Y, post[index,"sigma"])
  data.frame(X$x_income, synthetic_Y)
}

n <- dim(data)[1]
params <- data.frame(x_income, x_rural, x_race_B, x_race_N, x_race_A, x_race_P, x_race_M)
synthetic_one <- synthesize(params,1,n)
names(synthetic_one) <- c("OriginalIncome", "logIncome_syn")
plot(synthetic_one$OriginalIncome, synthetic_one$logIncome_syn)
mean(synthetic_one$OriginalIncome)
mean(synthetic_one$logIncome_syn)
sd(synthetic_one$OriginalIncome)
sd(synthetic_one$logIncome_syn)

```
The means for the original and synthetic income are fairly close (both approximately zero) and the standard deviations are also fairly close (both approximately one).
 











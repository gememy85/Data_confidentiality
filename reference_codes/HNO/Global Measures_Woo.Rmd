---
title: "Global Measures of Data Utility"
author: "Henrik Olsson"
date: "February 18, 2020"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
subtitle: MATH 301 Data Confidentiality
---

```{r include=FALSE}
library(readr)
library(LearnBayes)
library(plyr)
library(dplyr)
library(ggplot2)
library(runjags)
library(coda)
library(fastDummies)
library(tinytex)
library(MatchIt)
CEdata<- read.csv("CEdata.csv")
```


After reading the Woo paper on Global Measures of Data Utility and discussing with Kevin Ros, I attempted to implement the measures. The methods include Propensity Score Measure, Cluster Analysis Measure, and Empirical CDF Measures.

```{r include=FALSE}
CEdata$LogExp <- log(CEdata$Expenditure)
CEdata$LogIncome <- log(CEdata$Income)

## create indicator variable for Rural (2)
CEdata$Rural = fastDummies::dummy_cols(CEdata$UrbanRural)[,names(fastDummies::dummy_cols(CEdata$UrbanRural))
== ".data_1"]

## create indicator variables for Black (3), Native American (4), 
## Asian (5), Pacific Islander (6), and Multi-race (7)
CEdata$Race_Black = fastDummies::dummy_cols(CEdata$Race)[,names(fastDummies::dummy_cols(CEdata$Race)) == ".data_2"]
CEdata$Race_NA = fastDummies::dummy_cols(CEdata$Race)[,names(fastDummies::dummy_cols(CEdata$Race)) == ".data_3"]
CEdata$Race_Asian = fastDummies::dummy_cols(CEdata$Race)[,names(fastDummies::dummy_cols(CEdata$Race)) == ".data_4"]
CEdata$Race_PI = fastDummies::dummy_cols(CEdata$Race)[,names(fastDummies::dummy_cols(CEdata$Race)) == ".data_5"]
CEdata$Race_M = fastDummies::dummy_cols(CEdata$Race)[,names(fastDummies::dummy_cols(CEdata$Race)) == ".data_6"]

## JAGS script
modelString <-"
model {
## sampling
for (i in 1:N){
y[i] ~ dnorm(beta0 + beta1*x_income[i] + beta2*x_rural[i] +
beta3*x_race_B[i] + beta4*x_race_N[i] +
beta5*x_race_A[i] + beta6*x_race_P[i] +
beta7*x_race_M[i], invsigma2)
}
## priors
beta0 ~ dnorm(mu0, g0)
beta1 ~ dnorm(mu1, g1)
beta2 ~ dnorm(mu2, g2)
beta3 ~ dnorm(mu3, g3)
beta4 ~ dnorm(mu4, g4)
beta5 ~ dnorm(mu5, g5)
beta6 ~ dnorm(mu6, g6)
beta7 ~ dnorm(mu7, g7)
invsigma2 ~ dgamma(a, b)
sigma <- sqrt(pow(invsigma2, -1))
}"

y = as.vector(CEdata$LogExp)
x_income = as.vector(CEdata$LogIncome)
x_rural = as.vector(CEdata$Rural)
x_race_B = as.vector(CEdata$Race_Black)
x_race_N = as.vector(CEdata$Race_NA)
x_race_A = as.vector(CEdata$Race_Asian)
x_race_P = as.vector(CEdata$Race_PI)
x_race_M = as.vector(CEdata$Race_M)
N = length(y) # Compute the number of observations


## Pass the data and hyperparameter values to JAGS
the_data <- list("y" = y, "x_income" = x_income,
"x_rural" = x_rural, "x_race_B" = x_race_B,
"x_race_N" = x_race_N, "x_race_A" = x_race_A,
"x_race_P" = x_race_P, "x_race_M" = x_race_M,
"N" = N,
"mu0" = 0, "g0" = 1, "mu1" = 0, "g1" = 1,
"mu2" = 0, "g2" = 1, "mu3" = 0, "g3" = 1,
"mu4" = 0, "g4" = 1, "mu5" = 0, "g5" = 1,
"mu6" = 0, "g6" = 1, "mu7" = 0, "g7" = 1,
"a" = 1, "b" = 1)

initsfunction <- function(chain){
.RNG.seed <- c(1,2)[chain]
.RNG.name <- c("base::Super-Duper",
"base::Wichmann-Hill")[chain]
return(list(.RNG.seed=.RNG.seed,
.RNG.name=.RNG.name))
}

## Run the JAGS code for this model:
posterior_MLR <- run.jags(modelString,
n.chains = 1,
data = the_data,
monitor = c("beta0", "beta1", "beta2",
"beta3", "beta4", "beta5",
"beta6", "beta7", "sigma"),
adapt = 1000,
burnin = 5000,
sample = 5000,
thin = 1,
inits = initsfunction)


## Saving posterior parameter draws
post <- as.mcmc(posterior_MLR)

## Generating one set of sythetic data
synthesize <- function(X, index, n){
  mean_Y <- post[index, "beta0"] +  X$x_income * post[index, "beta1"] +  X$x_rural * post[index, "beta2"] +  X$x_race_B * post[index, "beta3"] +  X$x_race_N * post[index, "beta4"] +  X$x_race_A * post[index, "beta5"] +  X$x_race_P * post[index, "beta6"] +  X$x_race_M * post[index, "beta7"] 
  synthetic_Y <- rnorm(n, mean_Y, post[index, "sigma"])
  data.frame(X$x_income, synthetic_Y)
}
n <- dim(CEdata)[1]
new <- data.frame(x_income, x_rural, x_race_B, x_race_N, x_race_A, x_race_P, x_race_M)
synthetic_one <- synthesize(new, 1, n)
names(synthetic_one) <- c("OrigLogIncome", "SynLogIncome")
```

## Propensity Score Measure 

I attempted to generate the code for propensity score measures. First, we merge the original and synthetic datasets from the CEsample in HW 1. We must add variable T equal to one for the synthetic dataset and T equal to zero for the original dataset. 

```{r}
## Merge original and masked dataset (Method from Kevin Ros)
## Add variable T equal to 1 for synthetic dataset
one_data = rep(1, nrow(synthetic_one))
syn_data = data.frame(synthetic_one$SynLogIncome)
syn_data$T = one_data
colnames(syn_data)[colnames(syn_data) == "synthetic_one.SynLogIncome"] <- "Income"

## Add variable T equal to 0 for original dataset
zero_data = rep(0, nrow(synthetic_one))
orig_data = data.frame(synthetic_one$OrigLogIncome)
orig_data$T = zero_data
colnames(orig_data)[colnames(orig_data) == "synthetic_one.OrigLogIncome"] <- "Income"

merged_data = rbind(orig_data, syn_data)
head(merged_data,10)
```

Second, for each record in the original and masked data, we compute the probability of being in the masked data set, or the propensity score. We use the function MatchIt, which I found only to find the propensity score. 

```{r}
## Using the matchit function for propensity score, nearest neighbor matching
## Grouping variable is T and the variables being matched in Income (original and synthetic)
m.out = matchit(T ~ Income, data = merged_data, method = "nearest")
## Results of matchit saved in a variable called m.out
summary(m.out)
## propensity score plots
plot(m.out, type ="jitter")
plot(m.out, type ="hist")

## Fit a propensity score model. Logistic regression
psmodel <- glm(T ~ Income, family = "binomial", data = merged_data)

## Calculate the propensity score
c = 1/2
N = nrow(merged_data)
p_i <- psmodel$fitted.values
pscore = (p_i-c)^2
pscore = sum(pscore)/N
pscore
```

Nearest Neighbor method matches a treated unit to a control unit that is closest in terms of a distance measure such as logit.
The each dot in the jitterplot represent's a case's propensity score. The absence of cases in the upper stratification indicates that there were no unmatched treatment units. The middle stratifications show the close match between the treatment and matched control units. 
The histogram are before and after matching. They are very close. 

The propensity score is approximately 0.115, which close to 0.25 target to be completely distinguishable, but also close to 0, which completely matches the original data. 

## Cluster Analysis Measure

Cluster analysis places records into groups whose members have similar values of selected variables. We use O and M to denote the original and masked data, respectively. 

We first merge the original and masked datasets. Then we prespecify a value for G to be 20
```{r}
## Merge original and masked datasets (Taken from propensity score measure)

## Perform a cluster analysis on the merged data with a fixed number of groups G
## K-Means Cluster Analysis
fit <- kmeans(merged_data, 20)
## get cluster means
aggregate(merged_data,by=list(fit$cluster),FUN=mean)
## append cluster assignment
mydata <- data.frame(merged_data, fit$cluster)
## Then we calculate using the following measure 

```

If I could discover the code, I would try several values of G on the original dataset to examine the sensitivity to the choice G. 

## Empirical CDF Measures 


```{r}
plot(ecdf(merged_data$Income), xlab = "Income", ylab = "Fn(Income)")
```

The ecdf function shows the proportion of scores that are less than or equal to each score. The Fun means, in effect, "cumulative function".

```{r}
S_x = ecdf(synthetic_one$OrigLogIncome)
S_y = ecdf(synthetic_one$SynLogIncome)
diff = c()
for(i in 1:length(synthetic_one$OrigLogIncome)) {
  diff = c(diff, (synthetic_one$OrigLogIncome[i] - synthetic_one$SynLogIncome[i]))
}

## Calculation for U_m maximum absolute difference
max(diff)
```

This is definitely incorrect

```{r}
## Calculation for U_s (average squared differences)
for(i in 1:length(synthetic_one$OrigLogIncome)) {
  diff = c(diff, (synthetic_one$OrigLogIncome[i] - synthetic_one$SynLogIncome[i]))
}
sum(diff)/N
```

The drawback to using the CDF Empirical measure is that they can have low power to detect differences in distributions. Unfortunately, I am not sure how to accurately use this method. 
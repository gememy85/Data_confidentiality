---
title: "IPUMS Health Data"
author: "Henrik Olsson and Kevin Ros"
date: "April 19, 2020"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
subtitle: MATH 301 Data Confidentiality
---
```{r include=FALSE}
library(readr)
library(LearnBayes)
library(plyr)
library(dplyr)
library(ggplot2)
library(runjags)
library(coda)
#library(imputeTS)
library(fastDummies)
library(tinytex)
```

```{r}
## read data
#data <- read.csv("fulldataset.csv")
## REMOVE THIS LATER. ONLY TAKING 1000 SAMPLES B/C JAGS TOOK TOO LONG
#data <- sample_n(data, 2000, replace = FALSE, prob = NULL)
## log income
## data$LOGINC<- log(data$EARNIMPOINT1)
#save(data,file="tp.RData")
load("tp.RData")
```

Our goal is to generate synthetic data from the estimated Bayesian synthesizer from the posterior predictive distribution. To produce a good synthesizer, there will be trade-offs between utility and risks. 


```{r include=FALSE}
## Remove missing observations 
# packge won't install for me
#na.remove(data$AGE)
#na.remove(data$SEX)
#na.remove(data$RACEA)
#na.remove(data$EDUCREC2)
#na.remove(data$HOURSWRK)
#na.remove(data$EARNIMPOINT1)
#na.remove(data$HINOTCOVE)
#na.remove(data$HRSLEEP)
#na.remove(data$WORFREQ)
```

```{r}
## Remove all NIU (00) values
data <- data[!data$EDUCREC2 == 00, ]
data <- data[!data$HOURSWRK == 00, ]
data <- data[!data$HINOTCOVE == 0, ]
data <- data[!data$HRSLEEP == 00, ]
data <- data[!data$WORFREQ == 0, ]
```

```{r include=FALSE}
## Remove all 96 (900), 97 (970), 98 (980), 99s (990)
data <- data[!data$RACEA == 900, ]
data <- data[!data$RACEA == 970, ]
data <- data[!data$RACEA == 980, ]
data <- data[!data$RACEA == 990, ]
data <- data[!data$EDUCREC2 == 96, ]
data <- data[!data$EDUCREC2 == 97, ]
data <- data[!data$EDUCREC2 == 98, ]
data <- data[!data$EDUCREC2 == 99, ]
data <- data[!data$HOURSWRK == 97, ]
data <- data[!data$HOURSWRK == 98, ]
data <- data[!data$HOURSWRK == 99, ]
data <- data[!data$HINOTCOVE == 7, ]
data <- data[!data$HINOTCOVE == 8, ]
data <- data[!data$HINOTCOVE == 9, ]
data <- data[!data$HRSLEEP == 97, ]
data <- data[!data$HRSLEEP == 98, ]
data <- data[!data$HRSLEEP == 99, ]
data <- data[!data$WORFREQ == 7, ]
data <- data[!data$WORFREQ == 8, ]
data <- data[!data$WORFREQ == 9, ]
```

```{r}
## Create new column RACE and recode into 6 categories
## 1 = White, 2 = Black, 3 = American Indian, 4 = Asian, 
## 5 = Other races, 6 = Two or more races
data <- data %>% mutate(RACE = ifelse(RACEA %in% 100, 1, ifelse(RACEA %in% 200, 2, ifelse(RACEA %in% c(300,310,320,330,340), 3, ifelse(RACEA %in% c(400,410,411,412,413,414,415,416,420,421,422,423,430,431,432,433,434), 4,  ifelse(RACEA %in% c(500,510,520,530,540,550,560,570,580,600,610,611,612,613,614,615,616,617), 5, 0))))))
## Create new column EDUC and recode into 3 categories
## 1 = 4 years of high school or less, 2 = 4 years of college,
## 3 = 5+ years of college
data <- data %>% mutate(EDUC = ifelse(EDUCREC2 %in% c(10,20,30,31,32,40,41,42), 1, ifelse(EDUCREC2 %in% c(50,51,52,53,54), 2, ifelse(EDUCREC2 %in% 60, 3, 0))))
data <- data %>% mutate(INCOME = ifelse(EARNIMPOINT1 %in% 0, 0, 1))
```

```{r}
head(data)
summary(data)
```


```{r include=FALSE}
## create indicator variable for sex
data$SEX = fastDummies::dummy_cols(data$SEX)
## create indicator variables for race
data$RACE = fastDummies::dummy_cols(data$RACE)
## create indicator variables for education
data$EDUC = fastDummies::dummy_cols(data$EDUC)
## create indicator variables for healthcare coverage
data$HEALTH = fastDummies::dummy_cols(data$HINOTCOVE)
## create indicator variables for how often feel worried, nervous, or anxious
data$WORRY = fastDummies::dummy_cols(data$WORFREQ)
```

## Part 1: Synthetic Logistic Regression Model (syn income into 0 or non-zero)

```{r}
## JAGS script
modelString_part1 <-"
model {
## sampling
for(i in 1:N){
y[i] ~ dbern(p[i])
logit(p[i]) <- beta0 + beta1*x_age[i] +
beta2*x_sex_male[i] + beta3*x_sex_female[i] +
beta4*x_race_w[i] + beta5*x_race_b[i] +
beta6*x_race_i[i] + beta7*x_race_a[i] +
beta8*x_race_o[i] +
beta10*x_educ_1[i] + beta11*x_educ_2[i] +
beta12*x_educ_3[i] + beta13*x_hourswrk[i] +
beta14*x_health_cov[i] + beta15*x_health_nocov[i] +
beta16*x_hrsleep[i] + beta17*x_wor_daily[i] +
beta18*x_wor_weekly[i] + beta19*x_wor_monthly[i] +
beta20*x_wor_fewtimes[i] + beta21*x_wor_never[i]
}
## priors
beta0 ~ dnorm(mu0, g0)
beta1 ~ dnorm(mu1, g1)
beta2 ~ dnorm(mu2, g2)
beta3 ~ dnorm(mu3, g3)
beta4 ~ dnorm(mu4, g4)
beta5 ~ dnorm(mu5, g5)
beta6 ~ dnorm(mu6, g6)
beta7 ~ dnorm(mu7, g7)
beta8 ~ dnorm(mu8, g8)
beta10 ~ dnorm(mu10, g10)
beta11 ~ dnorm(mu11, g11)
beta12 ~ dnorm(mu12, g12)
beta13 ~ dnorm(mu13, g13)
beta14 ~ dnorm(mu14, g14)
beta15 ~ dnorm(mu15, g15)
beta16 ~ dnorm(mu16, g16)
beta17 ~ dnorm(mu17, g17)
beta18 ~ dnorm(mu18, g18)
beta19 ~ dnorm(mu19, g19)
beta20 ~ dnorm(mu20, g20)
beta21 ~ dnorm(mu21, g21)
}"
```

```{r}
y = as.vector(data$INCOME)
x_age = as.vector(data$AGE) ## age
x_sex_male = as.vector(data$SEX$.data_1) ## male
x_sex_female = as.vector(data$SEX$.data_2) ## female
x_race_w = as.vector(data$RACE$.data_1) ## white
x_race_b = as.vector(data$RACE$.data_2) ## black/african-american
x_race_i = as.vector(data$RACE$.data_3) ## american indian
x_race_a = as.vector(data$RACE$.data_4) ## asian
x_race_o = as.vector(data$RACE$.data_5) ## other races
x_educ_1 = as.vector(data$EDUC$.data_3) ## 4 years of high school or less
x_educ_2 = as.vector(data$EDUC$.data_1) ## 4 years of college
x_educ_3 = as.vector(data$EDUC$.data_2) ## 5+ years of college
x_hourswrk = as.vector(data$HOURSWRK) ## hours of work
x_health_cov = as.vector(data$HEALTH$.data_1) ## has health coverage
x_health_nocov = as.vector(data$HEALTH$.data_2) ## has no health coverage
x_hrsleep = as.vector(data$HRSLEEP) ## hours of sleep
x_wor_daily = as.vector(data$WORRY$.data_2) ## worry daily
x_wor_weekly = as.vector(data$WORRY$.data_5) ## worry weekly
x_wor_monthly = as.vector(data$WORRY$.data_4) ## worry monthly
x_wor_fewtimes = as.vector(data$WORRY$.data_3) ## worry few times a year
x_wor_never = as.vector(data$WORRY$.data_1) ## worry never
N = length(y) # Compute the number of observations
```

```{r}
## Pass the data and hyperparameter values to JAGS
the_data_part1 <- list("y" = y,
"x_age" = x_age, "x_sex_male" = x_sex_male,
"x_sex_female" = x_sex_female, "x_race_w" = x_race_w,
"x_race_b" = x_race_b, "x_race_i" = x_race_i,
"x_race_a" = x_race_a, "x_race_o" = x_race_o,
"x_educ_1" = x_educ_1,
"x_educ_2" = x_educ_2, "x_educ_3" = x_educ_3,
"x_hourswrk" = x_hourswrk, "x_health_cov" = x_health_cov,
"x_health_nocov" = x_health_nocov, "x_hrsleep" = x_hrsleep,
"x_wor_daily" = x_wor_daily, "x_wor_weekly" = x_wor_weekly,
"x_wor_monthly" = x_wor_monthly, "x_wor_fewtimes" = x_wor_fewtimes,
"x_wor_never" = x_wor_never, 
"N" = N,
"mu0" = 0, "g0" = 1, "mu1" = 0, "g1" = 1,
"mu2" = 0, "g2" = 1, "mu3" = 0, "g3" = 1,
"mu4" = 0, "g4" = 1, "mu5" = 0, "g5" = 1,
"mu6" = 0, "g6" = 1, "mu7" = 0, "g7" = 1,
"mu8" = 0, "g8" = 1, 
"mu10" = 0, "g10" = 1, "mu11" = 0, "g11" = 1,
"mu12" = 0, "g12" = 1, "mu13" = 0, "g13" = 1,
"mu14" = 0, "g14" = 1, "mu15" = 0, "g15" = 1,
"mu16" = 0, "g16" = 1, "mu17" = 0, "g17" = 1,
"mu18" = 0, "g18" = 1, "mu19" = 0, "g19" = 1,
"mu20" = 0, "g20" = 1, "mu21" = 0, "g21" = 1)
```

```{r}
initsfunction <- function(chain){
.RNG.seed <- c(1,2)[chain]
.RNG.name <- c("base::Super-Duper",
"base::Wichmann-Hill")[chain]
return(list(.RNG.seed=.RNG.seed,
.RNG.name=.RNG.name))
}
## Run the JAGS code for this model:
posterior_MLR <- run.jags(modelString_part1,
n.chains = 1,
data = the_data_part1,
monitor = c("beta0", "beta1", "beta2",
"beta3", "beta4", "beta5",
"beta6", "beta7", "beta8", "beta10",
"beta11", "beta12", "beta13", "beta14", "beta15", "beta16", "beta17",
"beta18", "beta19", "beta20", "beta21"),
adapt = 1000,
burnin = 5000,
sample = 5000,
thin = 1,
inits = initsfunction)
## JAGS output 
summary(posterior_MLR)
```

```{r}
plot(posterior_MLR, vars = "beta1")
```

```{r}
## Saving posterior parameter draws
post <- as.mcmc(posterior_MLR)
```

```{r}
## Generating one set of sythetic data
synthesize_catIncome <- function(X, index, n){
  synthetic_Y <- c()
  for(i in 1:n){
     p <- plogis(post[index, "beta0"] +  X$x_age[i] * post[index, "beta1"] +  X$x_sex_male[i] * post[index, "beta2"] +  X$x_sex_female[i] * post[index, "beta3"] +  X$x_race_w[i] * post[index, "beta4"] +  X$x_race_b[i] * post[index, "beta5"] +  X$x_race_i[i] * post[index, "beta6"] +  X$x_race_a[i] * post[index, "beta7"] +  X$x_race_o[i] * post[index, "beta8"] +  X$x_educ_1[i] * post[index, "beta10"] +  X$x_educ_2[i] * post[index, "beta11"] +  X$x_educ_3[i] * post[index, "beta12"] +  X$x_hourswrk[i] * post[index, "beta13"] +  X$x_health_cov[i] * post[index, "beta14"] +  X$x_health_nocov[i] * post[index, "beta15"] +  X$x_hrsleep[i] * post[index, "beta16"] +  X$x_wor_daily[i] * post[index, "beta17"] +  X$x_wor_weekly[i] * post[index, "beta18"] +  X$x_wor_monthly[i] * post[index, "beta19"] +  X$x_wor_fewtimes[i] * post[index, "beta20"] +  X$x_wor_never[i] * post[index, "beta21"])
     synthetic_Y[i] <- rbinom(1,1,p)
  }
  data.frame(X$y, synthetic_Y)
}
n <- dim(data)[1]
params <- data.frame(y, x_age, x_sex_male, x_sex_female, x_race_w, x_race_b, x_race_i, x_race_a, x_race_o, x_educ_1, x_educ_2, x_educ_3, x_hourswrk, x_health_cov, x_health_nocov, x_hrsleep, x_wor_daily, x_wor_weekly, x_wor_monthly, x_wor_fewtimes, x_wor_never)
synthetic_part1 <- synthesize_catIncome(params, 1, n)
names(synthetic_part1) <- c("CatIncome", "CatIncomeSyn")
```

```{r}
hist(synthetic_part1$CatIncome)
hist(synthetic_part1$CatIncomeSyn)
```

```{r}
## Remove unwanted columns
data$RACEA <- NULL
data$EDUCREC2 <- NULL
data$POORYN <- NULL
data$EARNIMP1 <- NULL
data$USUALPL <- NULL
data$DELAYCOST <- NULL
data$HINOTCOVE <- NULL
data$ALCDAYSWK <- NULL
data$CIGDAYMO <- NULL
data$DEPFREQ <- NULL
data$WORFREQ <- NULL
data$INCOME <- NULL
# Expand dataframe columns
data$SEX_1 <- data$SEX$.data_1
data$SEX_2 <- data$SEX$.data_2
data$SEX <- NULL
data$RACE_1 <- data$RACE$.data_1
data$RACE_2 <- data$RACE$.data_2
data$RACE_3 <- data$RACE$.data_3
data$RACE_4 <- data$RACE$.data_4
data$RACE_5 <- data$RACE$.data_5
data$RACE <- NULL
data$EDUC_1 <- data$EDUC$.data_1
data$EDUC_2 <- data$EDUC$.data_2
data$EDUC_3 <- data$EDUC$.data_3
data$EDUC <- NULL
data$HEALTH_1 <- data$HEALTH$.data_1
data$HEALTH_2 <- data$HEALTH$.data_2
data$HEALTH <- NULL
data$WORRY_1 = data$WORRY$.data_1
data$WORRY_2 = data$WORRY$.data_2
data$WORRY_3 = data$WORRY$.data_3
data$WORRY_4 = data$WORRY$.data_4
data$WORRY_5 = data$WORRY$.data_5
data$WORRY <- NULL
## Bind CatIncome to original data
data_org1 <- cbind(data, synthetic_part1$CatIncome)
## Bind CatIncomeSyn to synthetic data
data_syn1 <- cbind(data, synthetic_part1$CatIncomeSyn)
## Rename CatIncome and CatIncomeSyn
colnames(data_org1)[colnames(data_org1) == "synthetic_part1$CatIncome"] <- "INCOME"
colnames(data_syn1)[colnames(data_syn1) == "synthetic_part1$CatIncomeSyn"] <- "INCOME"
colnames(data_org1)
colnames(data_syn1)
```

# Utility evaluation - Global measures
```{r}
n <- dim(data_org1)[1]
merged_data1 <- rbind(data_org1,data_syn1)
merged_data1$S <- c(rep(0,n),rep(1,n))
# Propensity score (note we can't really take the log because of zero income values)
log_reg <- glm(S ~ AGE + HOURSWRK + HRSLEEP + SEX_1 + SEX_2 + RACE_1 + RACE_2 + RACE_3 + RACE_4 + RACE_5 + EDUC_1 + EDUC_2 + EDUC_3 + HEALTH_1 + HEALTH_2 + WORRY_1 + WORRY_2 + WORRY_3 + WORRY_4 + WORRY_5 + INCOME, family = "binomial", data = merged_data1)
pred <- predict(log_reg, data = merged_data1)
probs <- pred/(1+pred)
Up <- 1/(2*n)*sum((probs - 1/2)^2)
Up
```
```{r}
# Cluster analysis
clusters <- hclust(dist(merged_data1[,1:21]), method = 'average')
G <- 5
clusterCut <-cutree(clusters,G)
cluster_S <- as.data.frame(cbind(clusterCut, merged_data1$S))
names(cluster_S) <- c("cluster","S")
table(cluster_S)
```
```{r}
n_gS <- table(cluster_S)[,1]
n_g <- rowSums(table(cluster_S))
w_g <- n_g / (2*n)
Uc <- (1/G) * sum(w_g * (n_gS/n_g - 1/2)^2)
Uc
```
# Emperical CDF
```{r}
ecdf_orig <- ecdf(data_org1$INCOME)
ecdf_syn <- ecdf(data_syn1$INCOME)
percentile_orig <- ecdf_orig(merged_data1$INCOME)
percentile_syn <- ecdf_syn(merged_data1$INCOME)
ecdf_diff <- percentile_orig - percentile_syn
Um <- max(abs(ecdf_diff))
Um
```
```{r}
Ua <- mean(ecdf_diff^2)
Ua
```


1) Take all rows where income was syn to 1 above
2) Take all rows where income was orig non-zero
3) Log 2), use it in JAGS
4) Use model from 3) to syn all rows in 1)
5) Combine and evaluate data

## Part 2: Synthetic Linear Regression Model (syn income given all non-zero entries from part 1)

```{r}
## JAGS script
modelString_part2 <-"
model {
## sampling
for (i in 1:N){
y[i] ~ dnorm(beta0 + beta1*x_age[i] +
beta2*x_sex_male[i] + beta3*x_sex_female[i] +
beta4*x_race_w[i] + beta5*x_race_b[i] +
beta6*x_race_i[i] + beta7*x_race_a[i] +
beta8*x_race_o[i] +
beta10*x_educ_1[i] + beta11*x_educ_2[i] +
beta12*x_educ_3[i] + beta13*x_hourswrk[i] +
beta14*x_health_cov[i] + beta15*x_health_nocov[i] +
beta16*x_hrsleep[i] + beta17*x_wor_daily[i] +
beta18*x_wor_weekly[i] + beta19*x_wor_monthly[i] +
beta20*x_wor_fewtimes[i] + beta21*x_wor_never[i], invsigma2)
}
## priors
beta0 ~ dnorm(mu0, g0)
beta1 ~ dnorm(mu1, g1)
beta2 ~ dnorm(mu2, g2)
beta3 ~ dnorm(mu3, g3)
beta4 ~ dnorm(mu4, g4)
beta5 ~ dnorm(mu5, g5)
beta6 ~ dnorm(mu6, g6)
beta7 ~ dnorm(mu7, g7)
beta8 ~ dnorm(mu8, g8)
beta10 ~ dnorm(mu10, g10)
beta11 ~ dnorm(mu11, g11)
beta12 ~ dnorm(mu12, g12)
beta13 ~ dnorm(mu13, g13)
beta14 ~ dnorm(mu14, g14)
beta15 ~ dnorm(mu15, g15)
beta16 ~ dnorm(mu16, g16)
beta17 ~ dnorm(mu17, g17)
beta18 ~ dnorm(mu18, g18)
beta19 ~ dnorm(mu19, g19)
beta20 ~ dnorm(mu20, g20)
beta21 ~ dnorm(mu21, g21)
invsigma2 ~ dgamma(a, b)
sigma <- sqrt(pow(invsigma2, -1))
}"
```

```{r}
dataNoZeros = data[!data$EARNIMPOINT1 == 0,]
y = log(dataNoZeros$EARNIMPOINT1)
x_age = as.vector(dataNoZeros$AGE) ## age
x_sex_male = as.vector(dataNoZeros$SEX_1) ## male
x_sex_female = as.vector(dataNoZeros$SEX_2) ## female
x_race_w = as.vector(dataNoZeros$RACE_1) ## white
x_race_b = as.vector(dataNoZeros$RACE_2) ## black/african-american
x_race_i = as.vector(dataNoZeros$RACE_3) ## american indian
x_race_a = as.vector(dataNoZeros$RACE_4) ## asian
x_race_o = as.vector(dataNoZeros$RACE_5) ## other races
x_educ_1 = as.vector(dataNoZeros$EDUC_3) ## 4 years of high school or less
x_educ_2 = as.vector(dataNoZeros$EDUC_1) ## 4 years of college
x_educ_3 = as.vector(dataNoZeros$EDUC_2) ## 5+ years of college
x_hourswrk = as.vector(dataNoZeros$HOURSWRK) ## hours of work
x_health_cov = as.vector(dataNoZeros$HEALTH_1) ## has health coverage
x_health_nocov = as.vector(dataNoZeros$HEALTH_2) ## has no health coverage
x_hrsleep = as.vector(dataNoZeros$HRSLEEP) ## hours of sleep
x_wor_daily = as.vector(dataNoZeros$WORRY_2) ## worry daily
x_wor_weekly = as.vector(dataNoZeros$WORRY_5) ## worry weekly
x_wor_monthly = as.vector(dataNoZeros$WORRY_4) ## worry monthly
x_wor_fewtimes = as.vector(dataNoZeros$WORRY_3) ## worry few times a year
x_wor_never = as.vector(dataNoZeros$WORRY_1) ## worry never
N = length(y) # Compute the number of observations
## Pass the data and hyperparameter values to JAGS
the_data_part2 <- list("y" = y,
"x_age" = x_age, "x_sex_male" = x_sex_male,
"x_sex_female" = x_sex_female, "x_race_w" = x_race_w,
"x_race_b" = x_race_b, "x_race_i" = x_race_i,
"x_race_a" = x_race_a, "x_race_o" = x_race_o,
"x_educ_1" = x_educ_1,
"x_educ_2" = x_educ_2, "x_educ_3" = x_educ_3,
"x_hourswrk" = x_hourswrk, "x_health_cov" = x_health_cov,
"x_health_nocov" = x_health_nocov, "x_hrsleep" = x_hrsleep,
"x_wor_daily" = x_wor_daily, "x_wor_weekly" = x_wor_weekly,
"x_wor_monthly" = x_wor_monthly, "x_wor_fewtimes" = x_wor_fewtimes,
"x_wor_never" = x_wor_never, 
"N" = N,
"mu0" = 0, "g0" = 1, "mu1" = 0, "g1" = 1,
"mu2" = 0, "g2" = 1, "mu3" = 0, "g3" = 1,
"mu4" = 0, "g4" = 1, "mu5" = 0, "g5" = 1,
"mu6" = 0, "g6" = 1, "mu7" = 0, "g7" = 1,
"mu8" = 0, "g8" = 1,
"mu10" = 0, "g10" = 1, "mu11" = 0, "g11" = 1,
"mu12" = 0, "g12" = 1, "mu13" = 0, "g13" = 1,
"mu14" = 0, "g14" = 1, "mu15" = 0, "g15" = 1,
"mu16" = 0, "g16" = 1, "mu17" = 0, "g17" = 1,
"mu18" = 0, "g18" = 1, "mu19" = 0, "g19" = 1,
"mu20" = 0, "g20" = 1, "mu21" = 0, "g21" = 1,
"a" = 1, "b" = 1)
```

````{r}
## Run the JAGS code for this model:
posterior_MLR <- run.jags(modelString_part2,
n.chains = 1,
data = the_data_part2,
monitor = c("beta0", "beta1", "beta2",
"beta3", "beta4", "beta5",
"beta6", "beta7", "beta8", "beta10",
"beta11", "beta12", "beta13", "beta14", "beta15", "beta16", "beta17",
"beta18", "beta19", "beta20", "beta21", "sigma"),
adapt = 1000,
burnin = 5000,
sample = 5000,
thin = 20,
inits = initsfunction)
## JAGS output 
summary(posterior_MLR)
```
```{r}
plot(posterior_MLR, vars = "beta1")
```
```{r}
## Saving posterior parameter draws
post <- as.mcmc(posterior_MLR)
```
```{r}
## Generating one set of sythetic data
synthesize <- function(X, index, n){
  mean_Y <- post[index, "beta0"] +  X$x_age * post[index, "beta1"] +  X$x_sex_male * post[index, "beta2"] +  X$x_sex_female * post[index, "beta3"] +  X$x_race_w * post[index, "beta4"] +  X$x_race_b * post[index, "beta5"] +  X$x_race_i * post[index, "beta6"] +  X$x_race_a * post[index, "beta7"] +  X$x_race_o * post[index, "beta8"] +  X$x_educ_1 * post[index, "beta10"] +  X$x_educ_2 * post[index, "beta11"] +  X$x_educ_3 * post[index, "beta12"] +  X$x_hourswrk * post[index, "beta13"] +  X$x_health_cov * post[index, "beta14"] +  X$x_health_nocov * post[index, "beta15"] +  X$x_hrsleep * post[index, "beta16"] +  X$x_wor_daily * post[index, "beta17"] +  X$x_wor_weekly * post[index, "beta18"] +  X$x_wor_monthly * post[index, "beta19"] +  X$x_wor_fewtimes * post[index, "beta20"] +  X$x_wor_never * post[index, "beta21"] 
  synthetic_Y <- rnorm(n, mean_Y, post[index, "sigma"])
  data.frame(data$EARNIMPOINT1, exp(synthetic_Y))
}
n <- dim(data)[1]
params <- data.frame(y, x_age, x_sex_male, x_sex_female, x_race_w, x_race_b, x_race_i, x_race_a, x_race_o, x_educ_1, x_educ_2, x_educ_3, x_hourswrk, x_health_cov, x_health_nocov, x_hrsleep, x_wor_daily, x_wor_weekly, x_wor_monthly, x_wor_fewtimes, x_wor_never)
synthetic_one <- synthesize(params, 1, n)
names(synthetic_one) <- c("OrigIncome", "SynIncome")
```
```{r}
for (i in 1:nrow(synthetic_one)){
  if (synthetic_part1$CatIncomeSyn[i] == 0) {
    synthetic_one$SynIncome[i] = 0
  }
  if (synthetic_one$SynIncome[i] > 150000){
    synthetic_one$SynIncome[i] = 150000
  }
}
```
```{r}
ggplot(synthetic_one, aes(x = OrigIncome, y = SynIncome)) + 
  geom_point(size = 1) + 
  labs(title = "Scatter plot of Synthetic Income vs Original Income") +
  theme_bw(base_size = 6, base_family = "") +
  coord_cartesian(xlim = c(0, 155000)) + 
  coord_cartesian(ylim = c(0, 155000))
```
```{r}
## Bind CatIncome to original data
data_org <- cbind(data, synthetic_one$OrigIncome)
## Bind CatIncomeSyn to synthetic data
data_syn <- cbind(data, synthetic_one$SynIncome)
## Rename CatIncome and CatIncomeSyn
colnames(data_org)[colnames(data_org) == "synthetic_one$OrigIncome"] <- "INCOME"
colnames(data_syn)[colnames(data_syn) == "synthetic_one$SynIncome"] <- "INCOME"
colnames(data_org)
colnames(data_syn)
```
TODO:
Utility evaluation
-global measures
  1) propensity score (5)
  2) cluster analysis (5)
  3) emperical cdf (5)
-analysis specific measures
  4) mean, median, etc. (6)
  5) syn data variability (multiple syn datasets generated) (6)
  6) interval overlap (6)
Risk evaluation
-identification disclosure
  7) expected match risk (7)
  8) true match rate (7)
  9) false match rate (7)
-attribute risk disclosure
  10) AR disclosure
CatIncome (do ?):
Currently working:
Need to implement: 
Final model (do all):
Currently working: 1,2,3,4,5,6,7,8,9
Need to implement: 10
# Utility evaluation - Global measures
```{r}
n <- dim(data_org)[1]
merged_data <- rbind(data_org,data_syn)
merged_data$S <- c(rep(0,n),rep(1,n))
# Propensity score (note we can't really take the log because of zero income values)
log_reg <- glm(S ~ AGE + HOURSWRK + HRSLEEP + SEX_1 + SEX_2 + RACE_1 + RACE_2 + RACE_3 + RACE_4 + RACE_5 + EDUC_1 + EDUC_2 + EDUC_3 + HEALTH_1 + HEALTH_2 + WORRY_1 + WORRY_2 + WORRY_3 + WORRY_4 + WORRY_5 + INCOME, family = "binomial", data = merged_data)
pred <- predict(log_reg, data = merged_data)
probs <- pred/(1+pred)
Up <- 1/(2*n)*sum((probs - 1/2)^2)
Up
```
```{r}
# Cluster analysis
clusters <- hclust(dist(merged_data[,1:21]), method = 'average')
G <- 5
clusterCut <-cutree(clusters,G)
cluster_S <- as.data.frame(cbind(clusterCut, merged_data$S))
names(cluster_S) <- c("cluster","S")
table(cluster_S)
```
```{r}
n_gS <- table(cluster_S)[,1]
n_g <- rowSums(table(cluster_S))
w_g <- n_g / (2*n)
Uc <- (1/G) * sum(w_g * (n_gS/n_g - 1/2)^2)
Uc
```
# Emperical CDF
```{r}
ecdf_orig <- ecdf(data_org$INCOME)
ecdf_syn <- ecdf(data_syn$INCOME)
percentile_orig <- ecdf_orig(merged_data$INCOME)
percentile_syn <- ecdf_syn(merged_data$INCOME)
ecdf_diff <- percentile_orig - percentile_syn
Um <- max(abs(ecdf_diff))
Um
```
```{r}
Ua <- mean(ecdf_diff^2)
Ua
```
# Utility evaluation - Analysis specific measures: Mean and median
```{r}
mean(data_org$INCOME)
mean(data_syn$INCOME)
```
```{r}
median(data_org$INCOME)
median(data_syn$INCOME)
```
# Utility evaluation - Analysis specific measures: Synthetic data variability
```{r}
synthesizeMany <- function(X, index, n){
  mean_Y <- post[index, "beta0"] +  X$x_age * post[index, "beta1"] +  X$x_sex_male * post[index, "beta2"] +  X$x_sex_female * post[index, "beta3"] +  X$x_race_w * post[index, "beta4"] +  X$x_race_b * post[index, "beta5"] +  X$x_race_i * post[index, "beta6"] +  X$x_race_a * post[index, "beta7"] +  X$x_race_o * post[index, "beta8"] +  X$x_educ_1 * post[index, "beta10"] +  X$x_educ_2 * post[index, "beta11"] +  X$x_educ_3 * post[index, "beta12"] +  X$x_hourswrk * post[index, "beta13"] +  X$x_health_cov * post[index, "beta14"] +  X$x_health_nocov * post[index, "beta15"] +  X$x_hrsleep * post[index, "beta16"] +  X$x_wor_daily * post[index, "beta17"] +  X$x_wor_weekly * post[index, "beta18"] +  X$x_wor_monthly * post[index, "beta19"] +  X$x_wor_fewtimes * post[index, "beta20"] +  X$x_wor_never * post[index, "beta21"] 
  synthetic_Y <- rnorm(n, mean_Y, post[index, "sigma"])
  data.frame(exp(synthetic_Y))
}
n <- dim(data)[1]
params <- data.frame(y, x_age, x_sex_male, x_sex_female, x_race_w, x_race_b, x_race_i, x_race_a, x_race_o, x_educ_1, x_educ_2, x_educ_3, x_hourswrk, x_health_cov, x_health_nocov, x_hrsleep, x_wor_daily, x_wor_weekly, x_wor_monthly, x_wor_fewtimes, x_wor_never)
m <- 20
synthetic_m <- vector("list",m)
for(i in 1:m){
  syn <- synthesizeMany(params,i,n)
  names(syn) <- c("SynIncome")
  for (k in 1:nrow(syn)){
    if (synthetic_part1$CatIncomeSyn[i] == 0) {
      syn$SynIncome[i] = 0
    }
    if (syn$SynIncome[i] > 150000){
      syn$SynIncome[i] = 150000
    }
  }
  synthetic_m[[i]] <- syn
}
q <- rep(NA,m)
v <- rep(NA,m)
for(i in 1:m){
  syn <- synthetic_m[[i]]
  q[i] <- mean(syn$SynIncome)
  v[i] <- var(syn$SynIncome)/n
}
q_bar_m <- mean(q)
b_m <- var(q)
v_bar_m <- mean(v)
T_p <- b_m / m + v_bar_m
v_p <- (m-1) * (1 + v_bar_m / (b_m /m))^2
q_bar_m
```
```{r}
t_score_syn <- qt(p = 0.975, df = v_p)
interval_syn <- c(q_bar_m - t_score_syn * sqrt(T_p), q_bar_m + t_score_syn * sqrt(T_p))
interval_syn
```
```{r}
mean_org <- mean(data_org$INCOME)
sd_org <- sd(data_org$INCOME)
t_score_org <- qt(p = 0.975, df = n-1)
mean_org
```
```{r}
interval_orig <- c(mean_org - t_score_org * sd_org / sqrt(n),
  mean_org + t_score_org * sd_org / sqrt(n))
interval_orig
```
# Utility evaluation - Analysis specific measures: Interval overlap
```{r}
L_s <- interval_syn[1]
U_s <- interval_syn[2]
L_o <- interval_orig[1]
U_o <- interval_orig[2]
L_i <- max(L_s,L_o)
U_i <- min(U_s,U_o)
I <- (U_i - L_i) / (2 * (U_o - L_o)) + (U_i - L_i) / (2 * (U_s - L_s))
I
```
# Risk evaluation - Identification disclosure: Expected match risk, True match rate, False match rate
```{r}
CalculateKeyQuantities <- function(origdata, syndata, known.vars, syn.vars, n){
  origdata <- origdata
  syndata <- syndata
  n <- n
  c_vector <- rep(NA, n)
  T_vector <- rep(NA, n)
  for (i in 1:n){
    match <- (eval(parse(text=paste("origdata$",syn.vars,"[i]==
                                      syndata$",syn.vars,sep="",collapse="&")))&
                  eval(parse(text=paste("origdata$",known.vars,"[i]==
                                        syndata$",known.vars,sep="",collapse="&"))))
    match.prob <- ifelse(match, 1/sum(match), 0)
   
    if (max(match.prob) > 0){
      c_vector[i] <- length(match.prob[match.prob == max(match.prob)])
    }
    else
      c_vector[i] <- 0
      T_vector[i] <- is.element(i, rownames(data)[match.prob == max(match.prob)])
  }
 
  K_vector <- (c_vector * T_vector == 1)
  F_vector <- (c_vector * (1 - T_vector) == 1)
  s <- length(c_vector[c_vector == 1 & is.na(c_vector) == FALSE])
 
  res_r <- list(c_vector = c_vector,
                T_vector = T_vector,
                K_vector = K_vector,
                F_vector = F_vector,
                s = s
  )
  return(res_r)
}


 known.vars <- c("SEX_2", "SEX_1", "RACE_2","RACE_1","RACE_5","RACE_4","RACE_3",  "AGE", "EDUC_3", "EDUC_1", "EDUC_2","HOURSWRK",  "HEALTH_1","HEALTH_2","HRSLEEP", "WORRY_3", "WORRY_5", "WORRY_4", "WORRY_1", "WORRY_2")
 syn.vars <- c("INCOME")
 n <- dim(data_org)[1]
 KeyQuantities <- CalculateKeyQuantities(data_org, data_syn,
                                        known.vars, syn.vars, n)


 IdentificationRisk <- function(c_vector, T_vector, K_vector, F_vector, s, N){
 
  nonzero_c_index <- which(c_vector > 0)
  exp_match_risk <- sum(1/c_vector[nonzero_c_index]*T_vector[nonzero_c_index])
  true_match_rate <- sum(na.omit(K_vector))/N
  false_match_rate <- sum(na.omit(F_vector))/s
  res_r <- list(exp_match_risk = exp_match_risk,
                true_match_rate = true_match_rate,
                false_match_rate = false_match_rate
  )
  return(res_r)
}

#- each record is a target, therefore ```N = n```
c_vector <- KeyQuantities[["c_vector"]]
T_vector <- KeyQuantities[["T_vector"]]
K_vector <- KeyQuantities[["K_vector"]]
F_vector <- KeyQuantities[["F_vector"]]
s <- KeyQuantities[["s"]]
N <- n
ThreeSummaries <- IdentificationRisk(c_vector, T_vector, K_vector, F_vector, s, N)
```

```{r}
ThreeSummaries[["exp_match_risk"]]
```

```{r}
ThreeSummaries[["true_match_rate"]]
```

```{r}
ThreeSummaries[["false_match_rate"]]
```

# Risk evaluation - Attribute risk disclosure
```{r}
# Assume all variables except for income are known
# But we cannot log the values! 
```

